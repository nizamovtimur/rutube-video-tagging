{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline для хакатона Rutube по задаче \"Теггирование видео\"\n",
    "\n",
    "В рамках данного ноутбука мы рассмотрим наивный подход к решению поставленной задачи: векторный поиск навания видео в базе векторов тегов.\n",
    "\n",
    "В конце есть пример получения sample_submission.csv - пример файла, который нужно загрузить на лидерборд.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np \n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Берем данные с id видео и его названием, также загружаем иерархические теги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['video_id', 'title'], dtype='object')\n",
      "  video_id                                              title\n",
      "0  video_0  Шульский VS Дамил. Пояс. Мурад VS Черкасов. Га...\n",
      "1  video_1  Тарасов VS Хейбати. Намитов VS Тарасов за пояс...\n",
      "2  video_2  Мурад и Черкасов кровавое побоище. Мага Исма в...\n",
      "3  video_3  Шульский vs Вагабов. Тарасов vs Стоун.Сушист Ф...\n",
      "4  video_4  Такой расклад. Эфир 54 | Таро | Ответы на ваши...\n",
      "  Уровень 1 (iab)         Уровень 2 (iab)      Уровень 3 (iab)\n",
      "0       Транспорт                     NaN                  NaN\n",
      "1       Транспорт  Типы кузова автомобиля                  NaN\n",
      "2       Транспорт  Типы кузова автомобиля  Грузовой автомобиль\n",
      "3       Транспорт  Типы кузова автомобиля                Седан\n",
      "4       Транспорт  Типы кузова автомобиля            Универсал\n",
      "Index(['Уровень 1 (iab)', 'Уровень 2 (iab)', 'Уровень 3 (iab)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train_data_categories.csv\", index_col=0)[['video_id', 'title']]\n",
    "taxonomy = pd.read_csv(\"IAB_tags.csv\")\n",
    "\n",
    "print(data.columns)\n",
    "print(data.head(5))\n",
    "\n",
    "print(taxonomy.head(5))\n",
    "print(taxonomy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для создания эмбеддинга берем русскоязычный Берт и загружаем в sentence transformer, который позволяет создавать эмбеддинг для всего предложения и сам обрезает его до максимально возможного числа токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name DeepPavlov/rubert-base-cased-sentence. Creating a new one with mean pooling.\n",
      "/home/kivanova/download_videos/venv_tagging/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('DeepPavlov/rubert-base-cased-sentence', )\n",
    "dim = 768 # размер вектора эмбеддинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создаем эмбеддинги для названий видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_vector'] = data['title'].apply(lambda l: model.encode(l, convert_to_tensor=True).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создаем векторы для тегов:\n",
    " Для каждого 1 уровня иерархии в отдельности и для следующих уровней формата уровень 1: уровень 2: уровень 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "611it [00:12, 48.02it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_tags():\n",
    "    tags = {}\n",
    "    for i, row in tqdm(taxonomy.iterrows()):\n",
    "        if isinstance(row['Уровень 1 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)']] = model.encode(row['Уровень 1 (iab)'], convert_to_tensor=True).cpu().numpy()#.tolist()\n",
    "        if isinstance(row['Уровень 2 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']] = model.encode(row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)'], convert_to_tensor=True).cpu().numpy()#.tolist()\n",
    "        if isinstance(row['Уровень 3 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']+\": \"+row['Уровень 3 (iab)']] = model.encode(row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']+\": \"+row['Уровень 3 (iab)'], convert_to_tensor=True).cpu().numpy()#.tolist()\n",
    "    return tags\n",
    "\n",
    "tags = get_tags()\n",
    "tags_list = list(tags.keys())\n",
    "vectors = np.array(list(tags.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем векторную базу faiss для эффективного векторного поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "610\n"
     ]
    }
   ],
   "source": [
    "index = faiss.index_factory(dim, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "print(index.ntotal)\n",
    "index.add(vectors)\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Смотрим несколько получившихся примеров \n",
    "Генерим по 3 близких предсказания для каждого названия видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [254.40851 253.18213 249.99191]\n",
      "PREDICTION_by_title ['Спорт: Бейсбол' 'Игры: Киберспорт' 'Спорт: Дартс']\n",
      "SAMPLE Шульский VS Дамил. Пояс. Мурад VS Черкасов. Гаджи VS Хадис. Бой? Т-34 и Джанго напали на Колтуна\n",
      "\n",
      "\n",
      "SCORES [267.3344  261.73672 252.35751]\n",
      "PREDICTION_by_title ['Спорт: Борьба' 'Спорт: Дартс' 'Спорт: Боевые искусства']\n",
      "SAMPLE Тарасов VS Хейбати. Намитов VS Тарасов за пояс. Ершов VS Назир. Движ Борца VS Сушист. Савилов. Хизир\n",
      "\n",
      "\n",
      "SCORES [278.13666 259.80603 259.1851 ]\n",
      "PREDICTION_by_title ['Массовая культура: Смерти знаменитостей'\n",
      " 'Еда и напитки: Пищевые аллергии'\n",
      " 'Семья и отношения: Смерть родственников']\n",
      "SAMPLE Мурад и Черкасов кровавое побоище. Мага Исма в шоке. КимЧи подрался с Фишером. Большой Папа Леденев.\n",
      "\n",
      "\n",
      "SCORES [249.82545 246.67255 246.15733]\n",
      "PREDICTION_by_title ['Спорт: Дартс' 'Спорт: Настольный теннис' 'Спорт: Крикет']\n",
      "SAMPLE Шульский vs Вагабов. Тарасов vs Стоун.Сушист Фара Кузьминов Адамов Большой Папа vs Зулузиньо.Вадимыч\n",
      "\n",
      "\n",
      "SCORES [251.88638 247.22667 243.46187]\n",
      "PREDICTION_by_title ['Хобби и интересы: Игры и головоломки: Карточные игры'\n",
      " 'Хобби и интересы: Игры и головоломки: Ролевые игры'\n",
      " 'Спорт: Покер и профессиональные азартные игры']\n",
      "SAMPLE Такой расклад. Эфир 54 | Таро | Ответы на ваши вопросы о том, что волнует здесь и сейчас\n",
      "\n",
      "\n",
      "SCORES [265.18906 264.72202 264.31177]\n",
      "PREDICTION_by_title ['Фильмы и анимация: Инди и артхаусное кино'\n",
      " 'Массовая культура: Скандалы знаменитостей'\n",
      " 'Фильмы и анимация: Криминал и детективы']\n",
      "SAMPLE МузЛофт-подкаст | Павел Артемьев. От стадионов до маленьких залов. Про «Корни» и карьеру актера\n",
      "\n",
      "\n",
      "SCORES [284.29175 281.07825 276.3649 ]\n",
      "PREDICTION_by_title ['Семья и отношения: Смерть родственников'\n",
      " 'Религия и духовность: Агностицизм' 'Семья и отношения: Развод']\n",
      "SAMPLE Гатчина. Молчание Сильвии\n",
      "\n",
      "\n",
      "SCORES [251.78549 251.50473 242.6773 ]\n",
      "PREDICTION_by_title ['Спорт: Рыбалка' 'Спорт: Лакросс'\n",
      " 'Хобби и интересы: Игры и головоломки: Настольные игры и головоломки']\n",
      "SAMPLE Люди у которых клюёт | Выпуск 54 | Как поймать пассивного окуня?\n",
      "\n",
      "\n",
      "SCORES [277.32343 269.34586 264.38507]\n",
      "PREDICTION_by_title ['Семья и отношения: Развод'\n",
      " 'Медицина: Медицинские направления: Алкогольная и наркотическая зависимость'\n",
      " 'Медицина: Медицинские направления: Простуда и грипп']\n",
      "SAMPLE Злые языки | Выпуск 2, Сезон 1 | Дикая  Мити Фомина\n",
      "\n",
      "\n",
      "SCORES [262.88452 262.87927 260.88486]\n",
      "PREDICTION_by_title ['Спорт: Катание на роликовых коньках'\n",
      " 'Спорт: Экстремальные виды спорта: Вейкбординг и водные лыжи'\n",
      " 'Игры: Жанры видеоигр: Фитнес и упражнения']\n",
      "SAMPLE Люди у которых клюёт | Выпуск 36 | Соревнования по ловле спиннингом с берега. Ультралайт в дугу\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topn = 3\n",
    "scores, predictions = index.search(np.array(data['title_vector'].to_list()[:10]), topn)\n",
    "for j, i in enumerate(predictions):\n",
    "    print(\"SCORES\", scores[j])\n",
    "    print(\"PREDICTION_by_title\", np.array(tags_list)[predictions[j]])\n",
    "    print(\"SAMPLE\", data['title'].to_list()[:10][j])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для формирования sample_submission будем брать только наилучшее предсказания для каждого видео\n",
    "Сейчас у вас уже есть sample_submission с нужными для скоринга video_id, но пока нет информации о видео, она появится ближе к концу хакатона\n",
    "Для примера прогоним через весь train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn=1\n",
    "sample_submission = pd.DataFrame(data=data['video_id'].to_list(), columns=['video_id'])\n",
    "sample_submission['predicted_tags']=np.nan\n",
    "sample_submission['predicted_tags'] = sample_submission['predicted_tags'].astype('object')\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    scores, predictions = index.search(np.array([row['title_vector']]), topn)\n",
    "    index_i = sample_submission[sample_submission.video_id == row.video_id].index\n",
    "    sample_submission.at[index_i[0], 'predicted_tags'] = [tags_list[predictions[0][0]]] # вытаскиваем предсказание из "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  video_id                                     predicted_tags\n",
      "0  video_0                                   [Спорт: Бейсбол]\n",
      "1  video_1                                    [Спорт: Борьба]\n",
      "2  video_2          [Массовая культура: Смерти знаменитостей]\n",
      "3  video_3                                     [Спорт: Дартс]\n",
      "4  video_4  [Хобби и интересы: Игры и головоломки: Карточн...\n"
     ]
    }
   ],
   "source": [
    "print(sample_submission.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### В predicted_tags нужно записывать list тегов, например ['Карьера: Cтажировки', 'Карьера: Составление резюме'] или ['Массовая культура: Сериалы']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"sample_submission.csv\", index_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tagging",
   "language": "python",
   "name": "venv_tagging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
